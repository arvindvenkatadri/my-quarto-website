{
  "hash": "2847727800efd6f7478113d548fcb28a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: <iconify-icon icon=\"ph:circles-three-fill\" width=\"1.2em\" height=\"1.2em\"></iconify-icon> <iconify-icon icon=\"gravity-ui:function\" width=\"1.2em\" height=\"1.2em\"></iconify-icon> Things at Right Angles\nsubtitle: \"\"\nsubject: \"\"\nabstract: \"\"\ndate: 12/April/2025\ndate-modified: \"2025-07-29\"\norder: 60\ncode-fold: true\ncategories:\n- Orthogonality\n- Perpendicular\n- Vector\n- Dot Product\ncitation: true\ndraft: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Introduction\n\nHuman beings since old seem to have had an affinity for things at right angles. The Pythagoras theorem is of course testament to that. And Eratosthenes' method of measuring the radius/circumference of the earth. But why does this angle seem \"right\" to us? And where does it show up in our lives? \n\nIn this brief module we will examine the idea of \"right-ness\" in several different natural phenomena, and application areas, to develop an intuition for how this an essential property that is supremely useful.\n\nSo where do we see this idea popping up?\n\n### Physics\n\n- In **free space** electromagnetic wave propagation, we have electric and magnetic fields making up the two components of the radiated wave. These are at right angles. \n- An object casts a near-zero shadow when the light source illuminating it is right above it, at 90 degrees from the horizontal (i.e perpendicular). \n\n### Geometry\n\n- Right-angled triangles and the Pythagoras theorem\n- When we draw a graph in Cartesian coordinates, we wish to represent quantities $(x,y)$ on a set of axes, which are usually drawn perpendicular to each other, to ensure that the variations along each axis ***does not cast a shadow*** on the other axis, and are therefore ***independent***. \n\n\n### Vectors\n- When vectors are right angles, their **dot-product** / **inner product** is zero. \n- When we compute the **cross product / outer product** of two vectors, the resultant vector is perpendicular to the **plane** containing the two vectors. \n- If we have a family of vectors in 2 or more dimensions such that they are all mutually perpendicular to any other vector in the family, these are called an ***orthogonal basis set*** of vectors. Such vectors can be used to create a coordinate space of their own, and any other vector can be generated as a **weighted sum** of these basis vectors. \n\n\n### Waveforms\n- When two (or more!) waveforms are multiplied together, and the product averaged over time, we obtain a **time correlation** of the two. If this happens to be zero, we classify the waveforms as being **orthogonal**. This is, sort of, the calculation of the \"shadow\" each waveform casts on the other. \n- When we have a **family** of time functions which are ***each mutually orthogonal*** to any other waveform from the family, we have what is called an ***orthogonal basis set*** of waveforms. Such waveforms can be used to create a **waveform space** of their own, and any other waveform can be generated as a **weighted sum** of these basis waveforms. \n\n## Uses of Orthogonality\n\n### Fourier Series and Laplace Transforms\n\n### Data Visualization\n\n### Machine Learning and Deep Learning\n- In a [Perceptron](../../100-AI/20-Perceptron/index.qmd), we have a `vector dot product` between the input and the weight vectors. \n- In an ML-Classification problem, we consider a dataset of points containing say two classes. Each row in the data is a vector, with $length = n(columns)$. We take a `vector` of ***weights*** of the same length, and take the vector dot-product of this fixed weight vector with each of the rwo-observations. The result of this operation is one dot-product number per observation in the data.\\\n    Now consider the values of these dot products. Is the dot product negative, or positive in value? Can we use that polarity to decide on which observation belongs to which class? This is at the heart of an ML algorithm called [Support Vector Machines](). \n- \n\n### Technology\n- GPS / CDMA: See here for a quick intro to [GPS](https://arvindvenkatadri.com/teaching/3-order-and-chaos/modules/5b-voronoi/#proximities-in-the-gps-system-1). The codes used in GPS are a *family* of digital sequences called **Gold codes**. These are also an orthogonal set with near-zero cross-correlation between any pair of sequences from the set. \n- Bluetooth\n\n## References\n\n\n## Readings\n\n1. Arvind V on Quora. (2016). *What is orthogonality of a signal?* <https://qr.ae/pATe4W>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}