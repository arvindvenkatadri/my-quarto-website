{
  "hash": "faef1b2c51582ae041957dd622fdc720",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate-modified: \"2025-07-29\"\ndate: 15/Apr/2025\ntitle: \"What is Convolution?\"\norder: 80\nsummary: \ntags:\n- Convolution\n\n---\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## {{< iconify icons8 idea >}} Inspiration\n\nConsider that you live in a high rise apartment complex. Have you heard an ambulance go by? How does the sound of the siren change as the ambulance approaches towards your dwelling and then goes past it to get lost amidst the surrounding buildings again?\n\nThe siren's **emitted** sound is always the **same**. It is the local surroundings and the *geometry of the echoes* that brings the **same** sound to your ears again and again, but in altered/weighted form. The sound from the ambulance goes all around, hits on or other of the buildings, reflects, and comes back to your ears **after a delay** and **weighted** by the *strength* of the echo geometry.\n\nWhat you hear is the ***overlapping*** of multiple, weighted copies of the sound emitted by the ambulance. As long as you have direct, i.e. non-reflected path from the ambulance to your ears, the echoes are *relatively subdued*. Once the vehicle gets right into your building complex and you lose the direct line-of-sight path, the echoes take over and the sound becomes a very confused mass that is barely recognizable.\n\n#### What is Convolution?\n\nAll right, what does this have to do with **convolution**? Let us make some definitions first:\n\n::: callout-important\n### Channel\nThe free-space medium plus the buildings and other things that reflect sound in our environment, are called the \"Channel\". The channel ascts as a conduit between a source (transmitter) and a receiver.\n:::\n\n::: callout-important\n### Impulse Response of the Channel\nThe geometry of the echoes that connect transmitter to receiver, including the bounces of the walls, the resulting path-delays, and weighting are together denoted as the **impulse response** of the *channel*. This is what the *channel* would put out at the receiver if the source transmitter were to emit a very-short-duration signal, like the squeak of a mouse. \n:::\n\nNow, most signals emitted by a source are usually not \"squeak-like\": the ambulance has a siren that continuously emits the wellknown sound. Such a continuous signal is capable of mathematically decomposed into a series of \"squeak-like\" signals, which we call ***impulses***.\n\nSo finally:\n\n::: callout-important\n### What is Convolution?\nEach impulse undergoes the same geometry path-delays and path-weightings posed by the *channel impulse response*. This is diagrammatically shown below:\n\n![Convolution](../../../../../materials/images/Convolution.drawio.png){#fig-convolution}\n\n\nWe see that impulses in the *input waveform* that arrive ***later*** undergo wieghting by the ***earliest*** of path-delays and path-weightings. This should give you an intuition, that mathematically, this is like taking a ***weighted average*** but with the sequence of weights ***inverted in time***!!! \n\nIf $in(t)$ is the emitted sound waveform, and $f(t)$ is the channel impulse response, we write the output of the channel as:\n\n$$\n\\Large{out(t) = \\int_{-\\infty}^{\\infty} in(t) * f(t-\\tau) *d\\tau}\n$${#eq-convolution}\n\nNote that we are integrating wrt ***delay*** $\\tau$; and $f$ uses negative $\\tau$ as its variable. Hence it is hence inverted in time, as shown in the bottom left of the @fig-convolution. \n:::\n\n## Convolution in Code\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n\n### Using p5.js\n\n\n### Using R\nWe'll see\n\n:::\n\n\n## {{< iconify mingcute thought-line >}} Wait, But Why?\n\n- [Perceptrons](../../100-AI/30-MLP/index.qmd) are a standard convolution operation. \n- Convolution is an operation that is crucial to the operation of [Convolutional Neural Networks](../../100-AI/60-Convnet/index.qmd). The early *(spatial) filter layers* in a CNN implement a convolution with impulse responses that learn to look for edges, curves and similar *canonical* pieces in an input image. \n- When we generate guitar-like sounds using the [Karplus-Strong Guitar Algorithm](../../35-Media/99-KarplusStrong/index.qmd), we are using a set of filters (with low-pass/band-pass impulse responses) in the feedback loop of a delay-line primed with random noise. \n- Convolution can be seen as a series of [Vector Dot Products](../../05-Maths/20-Vectors/index.qmd#what-is-the-inner-product) between two vectors sliding past each other. \n\n## {{< iconify ooui references-ltr >}} References\nTo be Written Up.\n\n\n::: {#refs style=\"font-size: 60%;\"}\n###### {{< iconify lucide package-check >}} R Package Citations\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nPackage       Version       Citation     \n------------  ------------  -------------\nkeras         2.15.0        @keras       \nsafetensors   0.1.2         @safetensors \ntensorflow    2.16.0.9000   @tensorflow  \n\n\n:::\n:::\n\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}