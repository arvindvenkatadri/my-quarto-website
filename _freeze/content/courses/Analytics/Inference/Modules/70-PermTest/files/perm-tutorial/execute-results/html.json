{
  "hash": "04e7bbd6f162a100b3e978077ec2e31d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Permutation Tests\"\nauthor: \"Arvind Venkatadri\"\ndate: 21/Nov/2022\ndate-modified: \"2025-07-17\"\nabstract: A bunch of case studies with Permutation Tests\ncode-fold: true\ncode-summary: \"Show the Code\"\ncode-copy: true\ncode-tools: true\ncode-line-numbers: true\ndf-print: paged\nexecute: \n  freeze: auto\n---\n\n\n\n### Permutations tests using mosaic::`shuffle()`\n\nThe `mosaic` package provides the `shuffle()` function as a synonym for\n`sample()`. When used without additional arguments, this will permute\nits first argument.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# library(mosaic)\nshuffle(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  3  8  1  2  6  5 10  4  9  7\n```\n\n\n:::\n:::\n\n\nApplying shuffle() to an *explanatory variable* in a model allows us to\ntest the null hypothesis that the explanatory variable has, in fact, no\nexplanatory power. This idea can be used to test\n\n-   the equivalence of two or more means,\n-   the equivalence of two or more proportions,\n-   whether a regression parameter is 0. (Correlations between two\n    variables) For example:\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nCoupled with `mosaic::do()` we can repeat a `shuffle` many times,\ncomputing a desired statistic each time we shuffle. The distribution of\nthis computed statistic is a NULL distribution, which can then be\ncompared with the observed statistic to decide upon the Hypothesis Test\nand p-value.\n\n## Permutation Tests\n\n### Case Study-1: Hot Wings Orders vs Gender\n\nA student conducted a study of hot wings and beer consumption at a Bar.\nShe asked patrons at the bar to record their consumption of hot wings\nand beer over the course of several hours. She wanted to know if people\nwho ate more hot wings would then drink more beer. In addition, she\ninvestigated whether or not gender had an impact on hot wings or beer\nconsumption.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nBeerwings <- read.csv(\"../../../../../../materials/data/resampling/Beerwings.csv\")\ninspect(Beerwings)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n    name     class levels  n missing\n1 Gender character      2 30       0\n                                   distribution\n1 F (50%), M (50%)                             \n\nquantitative variables:  \n      name   class min    Q1 median    Q3 max     mean        sd  n missing\n1       ID integer   1  8.25   15.5 22.75  30 15.50000  8.803408 30       0\n2 Hotwings integer   4  8.00   12.5 15.50  21 11.93333  4.784554 30       0\n3     Beer integer   0 24.00   30.0 36.00  48 26.20000 11.842064 30       0\n```\n\n\n:::\n:::\n\n\nLet us calculate the observed difference in `Hotwings` consumption\nbetween Males and Females ( `Gender`)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(Hotwings ~ Gender, data = Beerwings)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        F         M \n 9.333333 14.533333 \n```\n\n\n:::\n\n```{.r .cell-code}\nobs_diff_wings <- mosaic::diffmean(data = Beerwings, Hotwings ~ Gender)\nobs_diff_wings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndiffmean \n     5.2 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngf_boxplot(data = Beerwings, Hotwings ~ Gender, title = \"Hotwings Consumption by Gender\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=50% height=50%}\n:::\n:::\n\n\nThe observed difference in mean consumption of Hotwings between Males\nand Females is 5.2. Could this have occurred by chance? Here is our\nformulation of the Hypotheses:\n\n$$\nNULL\\ Hypothesis\\ H_0 => No\\Â difference\\ between\\ means\\ across\\ groups\\\\\nAlternative\\ Hypothesis\\\nH_a =>Significant\\ difference\\ between\\ the\\ means\\\n$$\n\nSo we perform a Permutation Test to check:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnull_dist_wings <- do(1000) * diffmean(Hotwings ~ shuffle(Gender), data = Beerwings)\nnull_dist_wings %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"diffmean\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-1.0666667\",\"_rn_\":\"1\"},{\"1\":\"2.8000000\",\"_rn_\":\"2\"},{\"1\":\"2.0000000\",\"_rn_\":\"3\"},{\"1\":\"-3.0666667\",\"_rn_\":\"4\"},{\"1\":\"0.9333333\",\"_rn_\":\"5\"},{\"1\":\"-0.6666667\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_wings, ~diffmean) %>%\n  gf_vline(xintercept = obs_diff_wings, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=50% height=50%}\n:::\n\n```{.r .cell-code}\nprop1(~ diffmean >= obs_diff_wings, data = null_dist_wings)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  prop_TRUE \n0.001998002 \n```\n\n\n:::\n:::\n\n\nThe $\\color{red}{red\\ line}$ shows the actual measured mean difference\nin Hot Wings consumption. The probability that our Permutation\ndistribution is able to equal or exceed that number is $0.001998002$ and\nwe have to reject the Null Hypothesis that the means are identical.\n\nTo test whether eating more hotwings would lead to increased beer\nconsumption, we need a regression model, which we can again test with a\npermutation test.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm(Beer ~ Hotwings, data = Beerwings)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Beer ~ Hotwings, data = Beerwings)\n\nCoefficients:\n(Intercept)     Hotwings  \n      3.040        1.941  \n```\n\n\n:::\n:::\n\n\n### Case Study-2: Verizon\n\nThe following example is used throughout this article. Verizon was an\nIncumbent Local Exchange Carrier (ILEC), responsible for maintaining\nland-line phone service in certain areas. Verizon also sold\nlong-distance service, as did a number of competitors, termed\nCompetitive Local Exchange Carriers (CLEC). When something went wrong,\nVerizon was responsible for repairs, and was supposed to make repairs as\nquickly for CLEC long-distance customers as for their own. The New York\nPublic Utilities Commission (PUC) monitored fairness by comparing repair\ntimes for Verizon and different CLECs, for different classes of repairs\nand time periods. In each case a hypothesis test was performed at the 1%\nsignificance level, to determine whether repairs for CLEC's customers\nwere significantly slower than for Verizon's customers. There were\nhundreds of such tests. If substantially more than 1% of the tests were\nsignificant, then Verizon would pay large penalties. These tests were\nperformed using t tests; Verizon proposed using permutation tests\ninstead.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nverizon <- read.csv(\"../../../../../../materials/data/resampling/Verizon.csv\")\ninspect(verizon)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n   name     class levels    n missing\n1 Group character      2 1687       0\n                                   distribution\n1 ILEC (98.6%), CLEC (1.4%)                    \n\nquantitative variables:  \n  name   class min   Q1 median   Q3   max     mean       sd    n missing\n1 Time numeric   0 0.75   3.63 7.35 191.6 8.522009 14.78848 1687       0\n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(Time ~ Group, data = verizon)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     CLEC      ILEC \n16.509130  8.411611 \n```\n\n\n:::\n\n```{.r .cell-code}\nobs_diff_verizon <- diffmean(Time ~ Group, data = verizon)\nobs_diff_verizon\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndiffmean \n-8.09752 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnull_dist_verizon <- do(1000) * diffmean(Time ~ shuffle(Group), data = verizon)\ngf_histogram(data = null_dist_verizon, ~diffmean) %>%\n  gf_vline(xintercept = obs_diff_wings, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=50% height=50%}\n:::\n\n```{.r .cell-code}\nprop1(~ diffmean >= obs_diff_wings, data = null_dist_verizon)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n prop_TRUE \n0.01098901 \n```\n\n\n:::\n:::\n\n\n### Case Story-3: Recidivism\n\nDo criminals released after a jail term commit crimes again?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrecidivism <- read.csv(\"../../../../../../materials/data/resampling/Recidivism.csv\")\ninspect(recidivism)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n     name     class levels     n missing\n1  Gender character      2 17019       3\n2     Age character      5 17019       3\n3   Age25 character      2 17019       3\n4 Offense character      2 17022       0\n5   Recid character      2 17022       0\n6    Type character      3 17022       0\n                                   distribution\n1 M (87.7%), F (12.3%)                         \n2 25-34 (36.6%), 35-44 (23.7%) ...             \n3 Over 25 (81.9%), Under 25 (18.1%)            \n4 Felony (80.6%), Misdemeanor (19.4%)          \n5 No (68.4%), Yes (31.6%)                      \n6 No Recidivism (68.4%), New (20.2%) ...       \n\nquantitative variables:  \n  name   class min  Q1 median  Q3  max     mean       sd    n missing\n1 Days integer   0 241    418 687 1095 473.3275 283.1393 5386   11636\n```\n\n\n:::\n:::\n\n\nThere are some missing values in the variable <tt> `Age25`</tt>. The\n<tt> `complete.cases`</tt> command gives the row numbers where values\nare not missing. We create a new data frame omitting the rows where\nthere is a missing value in the <tt> 'Age25' </tt> variable.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrecidivism_na <- recidivism %>% tidyr::drop_na(Age25)\n```\n:::\n\n\nAlso, the variable <tt>`Recid`</tt> is a factor variable coded \"Yes\" or\n\"No\". We convert it to a numeric variable of 1's and 0's.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrecidivism_na <- recidivism_na %>% mutate(Recid2 = ifelse(Recid == \"Yes\", 1, 0))\n\nobs_diff_recid <- diffmean(Recid2 ~ Age25, data = recidivism_na)\nobs_diff_recid\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  diffmean \n0.05919913 \n```\n\n\n:::\n\n```{.r .cell-code}\nnull_dist_recid <- do(1000) * diffmean(Recid2 ~ shuffle(Age25), data = recidivism_na)\n\ngf_histogram(~diffmean, data = null_dist_recid) %>%\n  gf_vline(xintercept = obs_diff_recid, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=50% height=50%}\n:::\n:::\n\n\n### Case Study-4: Matched Pairs: Results from a diving championship.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nDiving2017 <- read.csv(\"../../../../../../materials/data/resampling/Diving2017.csv\")\nhead(Diving2017)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Country\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Semifinal\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Final\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"CHEONG Jun Hoong\",\"2\":\"Malaysia\",\"3\":\"325.50\",\"4\":\"397.50\",\"_rn_\":\"1\"},{\"1\":\"SI Yajie\",\"2\":\"China\",\"3\":\"382.80\",\"4\":\"396.00\",\"_rn_\":\"2\"},{\"1\":\"REN Qian\",\"2\":\"China\",\"3\":\"367.50\",\"4\":\"391.95\",\"_rn_\":\"3\"},{\"1\":\"KIM Mi Rae\",\"2\":\"North Korea\",\"3\":\"346.00\",\"4\":\"385.55\",\"_rn_\":\"4\"},{\"1\":\"WU Melissa\",\"2\":\"Australia\",\"3\":\"318.70\",\"4\":\"370.20\",\"_rn_\":\"5\"},{\"1\":\"KIM Kuk Hyang\",\"2\":\"North Korea\",\"3\":\"360.85\",\"4\":\"360.00\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ninspect(Diving2017)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n     name     class levels  n missing\n1    Name character     12 12       0\n2 Country character      8 12       0\n                                   distribution\n1  SI Yajie (8.3%) ...                         \n2 Canada (16.7%), China (16.7%) ...            \n\nquantitative variables:  \n       name   class    min       Q1  median      Q3   max    mean       sd  n\n1 Semifinal numeric 313.70 322.2000 325.625 356.575 382.8 338.500 22.94946 12\n2     Final numeric 283.35 318.5875 358.925 387.150 397.5 350.475 40.02204 12\n  missing\n1       0\n2       0\n```\n\n\n:::\n:::\n\n\nThe data is made up of **paired** observations per swimmer. So we need\nto take the difference between the two swim records for *each* swimmer\nand then shuffle the differences to either polarity. Another way to look\nat this is to shuffle the records between `Semifinal` and `Final` on a\nper Swimmer basis.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nDiving2017\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Country\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Semifinal\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Final\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"CHEONG Jun Hoong\",\"2\":\"Malaysia\",\"3\":\"325.50\",\"4\":\"397.50\"},{\"1\":\"SI Yajie\",\"2\":\"China\",\"3\":\"382.80\",\"4\":\"396.00\"},{\"1\":\"REN Qian\",\"2\":\"China\",\"3\":\"367.50\",\"4\":\"391.95\"},{\"1\":\"KIM Mi Rae\",\"2\":\"North Korea\",\"3\":\"346.00\",\"4\":\"385.55\"},{\"1\":\"WU Melissa\",\"2\":\"Australia\",\"3\":\"318.70\",\"4\":\"370.20\"},{\"1\":\"KIM Kuk Hyang\",\"2\":\"North Korea\",\"3\":\"360.85\",\"4\":\"360.00\"},{\"1\":\"ITAHASHI Minami\",\"2\":\"Japan\",\"3\":\"313.70\",\"4\":\"357.85\"},{\"1\":\"BENFEITO Meaghan\",\"2\":\"Canada\",\"3\":\"355.15\",\"4\":\"331.40\"},{\"1\":\"PAMG Pandelela\",\"2\":\"Malaysia\",\"3\":\"322.75\",\"4\":\"322.40\"},{\"1\":\"CHAMANDY Olivia\",\"2\":\"Canada\",\"3\":\"320.55\",\"4\":\"307.15\"},{\"1\":\"PARRATTO Jessica\",\"2\":\"USA\",\"3\":\"322.75\",\"4\":\"302.35\"},{\"1\":\"MURILLO URREA Carolina\",\"2\":\"Colombia\",\"3\":\"325.75\",\"4\":\"283.35\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nDiving2017 %>% diffmean(data = ., Final ~ Semifinal, only.2 = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  318.7-313.7  320.55-318.7 322.75-320.55  325.5-322.75  325.75-325.5 \n       12.350       -63.050         5.225        85.125      -114.150 \n   346-325.75    355.15-346 360.85-355.15  367.5-360.85   382.8-367.5 \n      102.200       -54.150        28.600        31.950         4.050 \n```\n\n\n:::\n\n```{.r .cell-code}\nobs_diff_swim <- mean(~ Final - Semifinal, data = Diving2017)\nobs_diff_swim\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 11.975\n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npolarity <- c(rep(1, 6), rep(-1, 6))\npolarity\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1\n```\n\n\n:::\n\n```{.r .cell-code}\nnull_dist_swim <- do(100000) * mean(\n  data = Diving2017,\n  ~ (Final - Semifinal) * resample(polarity,\n    replace = TRUE\n  )\n)\nnull_dist_swim %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"3.058333\",\"_rn_\":\"1\"},{\"1\":\"7.475000\",\"_rn_\":\"2\"},{\"1\":\"-17.908333\",\"_rn_\":\"3\"},{\"1\":\"-16.725000\",\"_rn_\":\"4\"},{\"1\":\"-13.916667\",\"_rn_\":\"5\"},{\"1\":\"-1.025000\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_swim, ~mean) %>%\n  gf_vline(xintercept = obs_diff_swim, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=50% height=50%}\n:::\n:::\n\n\n### Case Study #5: Flight Delays\n\nLaGuardia Airport (LGA) is one of three major airports that serves the\nNew York City metropolitan area. In 2008, over 23 million passengers and\nover 375 000 planes flew in or out of LGA. United Airlines and America\nAirlines are two major airlines that schedule services at LGA. The data\nset `FlightDelays` contains information on all 4029 departures of these\ntwo airlines from LGA during May and June 2009.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nflightDelays <- read.csv(\"../../../../../../materials/data/resampling/FlightDelays.csv\")\n\ninspect(flightDelays)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n         name     class levels    n missing\n1     Carrier character      2 4029       0\n2 Destination character      7 4029       0\n3  DepartTime character      5 4029       0\n4         Day character      7 4029       0\n5       Month character      2 4029       0\n6   Delayed30 character      2 4029       0\n                                   distribution\n1 AA (72.1%), UA (27.9%)                       \n2 ORD (44.3%), DFW (22.8%), MIA (15.1%) ...    \n3 8-Noon (26.1%), Noon-4pm (26%) ...           \n4 Fri (15.8%), Mon (15.6%), Tue (15.6%) ...    \n5 June (50.4%), May (49.6%)                    \n6 No (85.2%), Yes (14.8%)                      \n\nquantitative variables:  \n          name   class min   Q1 median   Q3  max      mean         sd    n\n1           ID integer   1 1008   2015 3022 4029 2015.0000 1163.21645 4029\n2     FlightNo integer  71  371    691  787 2255  827.1035  551.30939 4029\n3 FlightLength integer  68  155    163  228  295  185.3011   41.78783 4029\n4        Delay integer -19   -6     -3    5  693   11.7379   41.63050 4029\n  missing\n1       0\n2       0\n3       0\n4       0\n```\n\n\n:::\n:::\n\n\nThe variables in the `flightDelays` dataset are:\n\n| Variable     | Description                                                 |\n|--------------|-------------------------------------------------------------|\n| Carrier      | UA=United Airlines, AA=American Airlines                    |\n| FlightNo     | Flight number                                               |\n| Destination  | Airport code                                                |\n| DepartTime   | Scheduled departure time in 4 h intervals                   |\n| Day          | Day of the Week                                             |\n| Month        | May or June                                                 |\n| Delay        | Minutes flight delayed (negative indicates early departure) |\n| Delayed30    | Departure delayed more than 30 min? Yes or No               |\n| FlightLength | Length of time of flight (minutes)                          |\n\n: flightDelay dataset variables\n\na)  Let us compute the proportion of times that each carrier's flights\n    was delayed more than 20 min. We will conduct a two-sided test to\n    see if the difference in these proportions is statistically\n    significant.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprop(data = flightDelays, Delay >= 20 ~ Carrier)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nprop_TRUE.AA prop_TRUE.UA \n   0.1713696    0.2226180 \n```\n\n\n:::\n\n```{.r .cell-code}\nobs_diff_delay <- diffprop(data = flightDelays, Delay >= 20 ~ Carrier)\nobs_diff_delay\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  diffprop \n0.05124841 \n```\n\n\n:::\n:::\n\n\nWe see carrier AA has a 17.13% chance of delays\\>= 20, while UA has\n22.26% chance. The difference is 5.12%. Is this statistically\nsignificant? We take the Delays for both Carriers and perform a\npermutation test by `shuffle` on the `carrier` variable:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnull_dist_delay <- do(10000) * diffprop(data = flightDelays, Delay >= 20 ~ shuffle(Carrier))\nnull_dist_delay %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"diffprop\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.004308033\",\"_rn_\":\"1\"},{\"1\":\"-0.020357672\",\"_rn_\":\"2\"},{\"1\":\"-0.004308033\",\"_rn_\":\"3\"},{\"1\":\"-0.015419322\",\"_rn_\":\"4\"},{\"1\":\"0.012976193\",\"_rn_\":\"5\"},{\"1\":\"-0.014184734\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_delay, ~diffprop) %>% gf_vline(xintercept = obs_diff_delay, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=50% height=50%}\n:::\n:::\n\n\nIt appears that the difference indelay times is significant. We can\ncompute the `p-value` based on this test:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n2 * mean(null_dist_delay >= obs_diff_delay)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2e-04\n```\n\n\n:::\n:::\n\n\nwhich is very small. Hence we reject the null Hypothesis that there is\nno difference between `carrier`s on `delay times`.\n\nb)  Compute the variance in the flight delay lengths for each carrier.\n    Conduct a test to see if the variance for United Airlines differs\n    from that of American Airlines.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar(data = flightDelays, Delay ~ Carrier)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      AA       UA \n1606.457 2037.525 \n```\n\n\n:::\n\n```{.r .cell-code}\n# There is no readymade function in mosaic called `diffvar`...so...we construct one\nobs_diff_var <- diff(var(data = flightDelays, Delay ~ Carrier))\nobs_diff_var\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      UA \n431.0677 \n```\n\n\n:::\n:::\n\n\nThe difference in variances in `Delay` between the two `carrier`s is\n$-431.0677$. In our Permutation Test, we `shuffle` the `Carrier`\nvariable:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nobs_diff_var <- diff(var(data = flightDelays, Delay ~ Carrier))\nnull_dist_var <-\n  do(10000) * diff(var(data = flightDelays, Delay ~ shuffle(Carrier)))\nnull_dist_var %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"UA\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-40.879240\",\"_rn_\":\"1\"},{\"1\":\"638.716204\",\"_rn_\":\"2\"},{\"1\":\"5.324431\",\"_rn_\":\"3\"},{\"1\":\"18.335701\",\"_rn_\":\"4\"},{\"1\":\"-182.813199\",\"_rn_\":\"5\"},{\"1\":\"-113.407376\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# The null distribution variable is called `UA`\ngf_histogram(data = null_dist_var, ~UA) %>% gf_vline(xintercept = obs_diff_delay, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=50% height=50%}\n:::\n\n```{.r .cell-code}\n2 * mean(null_dist_var >= obs_diff_var)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3022\n```\n\n\n:::\n:::\n\n\nClearly there is no case for a significant difference in variances!\n\n### Case Study #6: Walmart vs Target\n\nIs there a difference in the price of groceries sold by the two\nretailers Target and Walmart? The data set `Groceries` contains a sample\nof grocery items and their prices advertised on their respective web\nsites on one specific day.\n\na)  Inspect the data set, then explain why this is an example of matched\n    pairs data.\nb)  Compute summary statistics of the prices for each store.\nc)  Conduct a permutation test to determine whether or not there is a\n    difference in the mean prices.\nd)  Create a ~~histogram~~ bar-chart of the difference in prices. What\n    is unusual about Quaker Oats Life cereal?\ne)  Redo the hypothesis test without this observation. Do you reach the\n    same conclusion?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngroceries <- read.csv(\"../../../../../../materials/data/resampling/Groceries.csv\") %>% mutate(Product = stringr::str_squish(Product))\nhead(groceries)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Product\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Size\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Target\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Walmart\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Kellogg NutriGrain Bars\",\"2\":\"8 bars\",\"3\":\"2.50\",\"4\":\"2.78\",\"_rn_\":\"1\"},{\"1\":\"Quaker Oats Life Cereal Original\",\"2\":\"18oz\",\"3\":\"3.19\",\"4\":\"6.01\",\"_rn_\":\"2\"},{\"1\":\"General Mills Lucky Charms\",\"2\":\"11.50z\",\"3\":\"3.19\",\"4\":\"2.98\",\"_rn_\":\"3\"},{\"1\":\"Quaker Oats Old Fashioned\",\"2\":\"18oz\",\"3\":\"2.82\",\"4\":\"2.68\",\"_rn_\":\"4\"},{\"1\":\"Nabisco Oreo Cookies\",\"2\":\"14.3oz\",\"3\":\"2.99\",\"4\":\"2.98\",\"_rn_\":\"5\"},{\"1\":\"Nabisco Chips Ahoy\",\"2\":\"13oz\",\"3\":\"2.64\",\"4\":\"1.98\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ninspect(groceries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n     name     class levels  n missing\n1 Product character     30 30       0\n2    Size character     24 30       0\n                                   distribution\n1 Annie's Macaroni & Cheese (3.3%) ...         \n2 18oz (10%), 12oz (6.7%) ...                  \n\nquantitative variables:  \n     name   class  min     Q1 median    Q3  max     mean       sd  n missing\n1  Target numeric 0.99 1.8275  2.545 3.140 7.99 2.762333 1.582128 30       0\n2 Walmart numeric 1.00 1.7600  2.340 2.955 6.98 2.705667 1.560211 30       0\n```\n\n\n:::\n:::\n\n\nWe see that the comparison is to be made between two prices for the\n*same* product, and hence this is one more example of `paired data`, as\nin Case Study #4. Let us plot the prices for the products:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngf_col(\n  data = groceries,\n  Target ~ Product,\n  fill = \"#0073C299\",\n  width = 0.5\n) %>%\n  gf_col(\n    data = groceries,\n    -Walmart ~ Product,\n    fill = \"#EFC00099\",\n    ylab = \"Prices\",\n    width = 0.5\n  ) %>%\n  gf_col(\n    data = groceries %>% filter(Product == \"Quaker Oats Life Cereal Original\"),\n    -Walmart ~ Product,\n    fill = \"red\",\n    width = 0.5\n  ) %>%\n  gf_theme(theme_classic()) %>%\n  gf_theme(ggplot2::theme(axis.text.x = element_text(\n    size = 8,\n    face = \"bold\",\n    vjust = 0,\n    hjust = 1\n  ))) %>%\n  gf_theme(ggplot2::coord_flip())\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=50% height=50%}\n:::\n:::\n\n\nWe see that the price difference between Walmart and Target prices is\nhighest for the `Product` named `Quaker Oats Life Cereal Original`. Let\nus check the mean difference in prices:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndiffmean(data = groceries, Walmart ~ Target, only.2 = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   1-0.99    1.22-1 1.42-1.22 1.49-1.42 1.59-1.49 1.62-1.59 1.79-1.62 1.94-1.79 \n-0.580000  0.170000  0.210000 -0.100000  0.190000  0.070000  0.180000  0.160000 \n1.99-1.94 2.12-1.99 2.39-2.12  2.5-2.39  2.59-2.5 2.64-2.59 2.79-2.64 2.82-2.79 \n 0.090000  0.010000  0.200000  0.600000 -0.200000 -0.600000  0.660000  0.040000 \n2.99-2.82 3.19-2.99 3.49-3.19 3.99-3.49 4.79-3.99 7.19-4.79 7.99-7.19 \n 0.220000  1.263333 -1.183333 -0.480000  2.290000  2.190000  0.000000 \n```\n\n\n:::\n\n```{.r .cell-code}\nobs_diff_price <- mean(~ Walmart - Target, data = groceries)\nobs_diff_price\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.05666667\n```\n\n\n:::\n:::\n\n\nLet us perform the pair-wise permutation test on prices, by shuffling\nthe two store names:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npolarity <- c(rep(1, 15), rep(-1, 15))\npolarity\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n[26] -1 -1 -1 -1 -1\n```\n\n\n:::\n\n```{.r .cell-code}\nnull_dist_price <- do(100000) * mean(\n  data = groceries,\n  ~ (Walmart - Target) * resample(polarity,\n    replace = TRUE\n  )\n)\nnull_dist_price %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.07266667\",\"_rn_\":\"1\"},{\"1\":\"-0.02066667\",\"_rn_\":\"2\"},{\"1\":\"0.16933333\",\"_rn_\":\"3\"},{\"1\":\"0.05533333\",\"_rn_\":\"4\"},{\"1\":\"-0.05333333\",\"_rn_\":\"5\"},{\"1\":\"0.17333333\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_price, ~mean) %>%\n  gf_vline(xintercept = obs_diff_price, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=50% height=50%}\n:::\n\n```{.r .cell-code}\n2 * (sum(null_dist_price >= obs_diff_price + 1) / (100000 + 1)) # P-value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\nDoes not seem to be any significant difference in prices...\n\nSuppose we knock off the Quaker Cereal data item...\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwhich(groceries$Product == \"Quaker Oats Life Cereal Original\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n\n```{.r .cell-code}\ngroceries_less <- groceries[-2, ]\ngroceries_less\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Product\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Size\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Target\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Walmart\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Kellogg NutriGrain Bars\",\"2\":\"8 bars\",\"3\":\"2.50\",\"4\":\"2.78\",\"_rn_\":\"1\"},{\"1\":\"General Mills Lucky Charms\",\"2\":\"11.50z\",\"3\":\"3.19\",\"4\":\"2.98\",\"_rn_\":\"3\"},{\"1\":\"Quaker Oats Old Fashioned\",\"2\":\"18oz\",\"3\":\"2.82\",\"4\":\"2.68\",\"_rn_\":\"4\"},{\"1\":\"Nabisco Oreo Cookies\",\"2\":\"14.3oz\",\"3\":\"2.99\",\"4\":\"2.98\",\"_rn_\":\"5\"},{\"1\":\"Nabisco Chips Ahoy\",\"2\":\"13oz\",\"3\":\"2.64\",\"4\":\"1.98\",\"_rn_\":\"6\"},{\"1\":\"Doritos Nacho Cheese Chips\",\"2\":\"10oz\",\"3\":\"3.99\",\"4\":\"2.50\",\"_rn_\":\"7\"},{\"1\":\"Cheez-it Original Baked\",\"2\":\"21oz\",\"3\":\"4.79\",\"4\":\"4.79\",\"_rn_\":\"8\"},{\"1\":\"Swiss Miss Hot Chocolate\",\"2\":\"10 count\",\"3\":\"1.49\",\"4\":\"1.28\",\"_rn_\":\"9\"},{\"1\":\"Tazo Chai Classic Latte Black Tea\",\"2\":\"32 oz\",\"3\":\"3.49\",\"4\":\"2.98\",\"_rn_\":\"10\"},{\"1\":\"Annie's Macaroni & Cheese\",\"2\":\"6oz\",\"3\":\"1.79\",\"4\":\"1.72\",\"_rn_\":\"11\"},{\"1\":\"Rice A Roni Chicken\",\"2\":\"6.9oz\",\"3\":\"1.00\",\"4\":\"1.00\",\"_rn_\":\"12\"},{\"1\":\"Zatarain's Jambalaya Rice Mix\",\"2\":\"8oz\",\"3\":\"1.62\",\"4\":\"1.54\",\"_rn_\":\"13\"},{\"1\":\"SPAM Original Lunch Meat\",\"2\":\"12oz\",\"3\":\"2.79\",\"4\":\"2.64\",\"_rn_\":\"14\"},{\"1\":\"Campbell's Chicken Noodle Soup\",\"2\":\"10.75oz\",\"3\":\"0.99\",\"4\":\"1.58\",\"_rn_\":\"15\"},{\"1\":\"Dinty Moore Hearty Meals Beef Stew\",\"2\":\"15oz\",\"3\":\"1.99\",\"4\":\"1.98\",\"_rn_\":\"16\"},{\"1\":\"Hormel Chili with Beans\",\"2\":\"15oz\",\"3\":\"1.94\",\"4\":\"1.88\",\"_rn_\":\"17\"},{\"1\":\"Dole Pineapple Chunks\",\"2\":\"20 oz\",\"3\":\"1.59\",\"4\":\"1.47\",\"_rn_\":\"18\"},{\"1\":\"Skippy Creamy Peanut Butter\",\"2\":\"16.3oz\",\"3\":\"2.59\",\"4\":\"2.58\",\"_rn_\":\"19\"},{\"1\":\"Smucker's Strawberry Preserve\",\"2\":\"18oz\",\"3\":\"2.99\",\"4\":\"2.84\",\"_rn_\":\"20\"},{\"1\":\"Heinz Tomato Ketchup\",\"2\":\"32oz\",\"3\":\"2.99\",\"4\":\"2.88\",\"_rn_\":\"21\"},{\"1\":\"Near East Couscous Toasted Pine Nuts mix\",\"2\":\"5.6oz\",\"3\":\"2.12\",\"4\":\"1.98\",\"_rn_\":\"22\"},{\"1\":\"Barilla Angel Hair Pasta\",\"2\":\"16oz\",\"3\":\"1.42\",\"4\":\"1.38\",\"_rn_\":\"23\"},{\"1\":\"Betty Crocker Super Moist Chocolate Fudge Cake Mix\",\"2\":\"15.25oz\",\"3\":\"1.22\",\"4\":\"1.17\",\"_rn_\":\"24\"},{\"1\":\"Kraft Jet-Puffed Marshmllows\",\"2\":\"16oz\",\"3\":\"1.99\",\"4\":\"1.96\",\"_rn_\":\"25\"},{\"1\":\"Dunkin' Donuts Original Blend Medium Roast Ground Coffee\",\"2\":\"12oz\",\"3\":\"7.19\",\"4\":\"6.98\",\"_rn_\":\"26\"},{\"1\":\"Dove Promises Milk Chocolate\",\"2\":\"8.87oz\",\"3\":\"3.19\",\"4\":\"3.50\",\"_rn_\":\"27\"},{\"1\":\"Skittles\",\"2\":\"41oz\",\"3\":\"7.99\",\"4\":\"6.98\",\"_rn_\":\"28\"},{\"1\":\"Vlasic Kosher Dill Pickle Spears\",\"2\":\"24oz\",\"3\":\"2.39\",\"4\":\"2.18\",\"_rn_\":\"29\"},{\"1\":\"Vlasic Old Fashioned Sauerkraut\",\"2\":\"32oz\",\"3\":\"1.99\",\"4\":\"1.97\",\"_rn_\":\"30\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nobs_diff_price_less <- mean(~ Walmart - Target, data = groceries_less)\nobs_diff_price_less\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1558621\n```\n\n\n:::\n\n```{.r .cell-code}\npolarity_less <- c(rep(1, 15), rep(-1, 14)) # Due to resampling this small bias makes no difference\nnull_dist_price_less <- do(100000) * mean(\n  data = groceries_less,\n  ~ (Walmart - Target) * resample(polarity_less,\n    replace = TRUE\n  )\n)\nnull_dist_price_less %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.11724138\",\"_rn_\":\"1\"},{\"1\":\"0.05034483\",\"_rn_\":\"2\"},{\"1\":\"-0.05793103\",\"_rn_\":\"3\"},{\"1\":\"-0.08689655\",\"_rn_\":\"4\"},{\"1\":\"-0.11724138\",\"_rn_\":\"5\"},{\"1\":\"0.07517241\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_price_less, ~mean) %>%\n  gf_vline(xintercept = obs_diff_price_less, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=50% height=50%}\n:::\n\n```{.r .cell-code}\n1 - mean(null_dist_price_less >= obs_diff_price_less) # P-value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01584\n```\n\n\n:::\n:::\n\n\n### Case Study 7: Proportions between Categorical Variables\n\nLet us try a dataset with Qualitative / Categorical data. This is a\nGeneral Social Survey dataset, and we have people with different levels\nof `Education` stating their opinion on the `Death Penalty`. We want to\nknow if these two Categorical variables have a correlation, i.e. can the\nopinions in favour of the Death Penalty be explained by the Education\nlevel?\n\nSince data is Categorical, we need to take `counts` in a table, and then\nimplement a `chi-square test`. In the test, we will permute the\n`Education` variable to see if we can see how significant its *effect\nsize* is.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nGSS2002 <- read.csv(\"../../../../../../materials/data/resampling/GSS2002.csv\")\ninspect(GSS2002)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n            name     class levels    n missing\n1         Region character      7 2765       0\n2         Gender character      2 2765       0\n3           Race character      3 2765       0\n4      Education character      5 2760       5\n5        Marital character      5 2765       0\n6       Religion character     13 2746      19\n7          Happy character      3 1369    1396\n8         Income character     24 1875     890\n9       PolParty character      8 2729      36\n10      Politics character      7 1331    1434\n11     Marijuana character      2  851    1914\n12  DeathPenalty character      2 1308    1457\n13        OwnGun character      3  924    1841\n14        GunLaw character      2  916    1849\n15 SpendMilitary character      3 1324    1441\n16     SpendEduc character      3 1343    1422\n17      SpendEnv character      3 1322    1443\n18      SpendSci character      3 1266    1499\n19        Pres00 character      5 1749    1016\n20      Postlife character      2 1211    1554\n                                    distribution\n1  North Central (24.7%) ...                    \n2  Female (55.6%), Male (44.4%)                 \n3  White (79.1%), Black (14.8%) ...             \n4  HS (53.8%), Bachelors (16.1%) ...            \n5  Married (45.9%), Never Married (25.6%) ...   \n6  Protestant (53.2%), Catholic (24.5%) ...     \n7  Pretty happy (57.3%) ...                     \n8  40000-49999 (9.1%) ...                       \n9  Ind (19.3%), Not Str Dem (18.9%) ...         \n10 Moderate (39.2%), Conservative (15.8%) ...   \n11 Not legal (64%), Legal (36%)                 \n12 Favor (68.7%), Oppose (31.3%)                \n13 No (65.5%), Yes (33.5%) ...                  \n14 Favor (80.5%), Oppose (19.5%)                \n15 About right (46.5%) ...                      \n16 Too little (73.9%) ...                       \n17 Too little (60%) ...                         \n18 About right (49.7%) ...                      \n19 Bush (50.6%), Gore (44.7%) ...               \n20 Yes (80.5%), No (19.5%)                      \n\nquantitative variables:  \n  name   class min  Q1 median   Q3  max mean       sd    n missing\n1   ID integer   1 692   1383 2074 2765 1383 798.3311 2765       0\n```\n\n\n:::\n:::\n\n\nNote how *all* variables are Categorical !! `Education` has five\n`levels`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nGSS2002 %>% count(Education)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Education\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Bachelors\",\"2\":\"443\"},{\"1\":\"Graduate\",\"2\":\"230\"},{\"1\":\"HS\",\"2\":\"1485\"},{\"1\":\"Jr Col\",\"2\":\"202\"},{\"1\":\"Left HS\",\"2\":\"400\"},{\"1\":\"NA\",\"2\":\"5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nGSS2002 %>% count(DeathPenalty)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"DeathPenalty\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Favor\",\"2\":\"899\"},{\"1\":\"Oppose\",\"2\":\"409\"},{\"1\":\"NA\",\"2\":\"1457\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nLet us drop NA entries in Education and Death Penalty. And set up a\ntable for the chi-square test.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngss2002 <- GSS2002 %>%\n  dplyr::select(Education, DeathPenalty) %>%\n  tidyr::drop_na(., c(Education, DeathPenalty))\ndim(gss2002)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1307    2\n```\n\n\n:::\n\n```{.r .cell-code}\ngss_summary <- gss2002 %>%\n  mutate(\n    Education = factor(\n      Education,\n      levels = c(\"Bachelors\", \"Graduate\", \"Jr Col\", \"HS\", \"Left HS\"),\n      labels = c(\"Bachelors\", \"Graduate\", \"Jr Col\", \"HS\", \"Left HS\")\n    ),\n    DeathPenalty = as.factor(DeathPenalty)\n  ) %>%\n  group_by(Education, DeathPenalty) %>%\n  summarise(count = n()) %>% # This is good for a chisq test\n\n  # Add two more columns to faciltate mosaic/Marrimekko Plot\n  #\n  mutate(\n    edu_count = sum(count),\n    edu_prop = count / sum(count)\n  ) %>%\n  ungroup()\n\ngss_summary\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Education\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"DeathPenalty\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"count\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"edu_count\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"edu_prop\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Bachelors\",\"2\":\"Favor\",\"3\":\"135\",\"4\":\"206\",\"5\":\"0.6553398\"},{\"1\":\"Bachelors\",\"2\":\"Oppose\",\"3\":\"71\",\"4\":\"206\",\"5\":\"0.3446602\"},{\"1\":\"Graduate\",\"2\":\"Favor\",\"3\":\"64\",\"4\":\"114\",\"5\":\"0.5614035\"},{\"1\":\"Graduate\",\"2\":\"Oppose\",\"3\":\"50\",\"4\":\"114\",\"5\":\"0.4385965\"},{\"1\":\"Jr Col\",\"2\":\"Favor\",\"3\":\"71\",\"4\":\"87\",\"5\":\"0.8160920\"},{\"1\":\"Jr Col\",\"2\":\"Oppose\",\"3\":\"16\",\"4\":\"87\",\"5\":\"0.1839080\"},{\"1\":\"HS\",\"2\":\"Favor\",\"3\":\"511\",\"4\":\"711\",\"5\":\"0.7187060\"},{\"1\":\"HS\",\"2\":\"Oppose\",\"3\":\"200\",\"4\":\"711\",\"5\":\"0.2812940\"},{\"1\":\"Left HS\",\"2\":\"Favor\",\"3\":\"117\",\"4\":\"189\",\"5\":\"0.6190476\"},{\"1\":\"Left HS\",\"2\":\"Oppose\",\"3\":\"72\",\"4\":\"189\",\"5\":\"0.3809524\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# We can plot a heatmap-like `mosaic chart` for this table, using `ggplot`:\n# https://stackoverflow.com/questions/19233365/how-to-create-a-marimekko-mosaic-plot-in-ggplot2\n\nggplot(data = gss_summary, aes(x = Education, y = edu_prop)) +\n  geom_bar(aes(width = edu_count, fill = DeathPenalty), stat = \"identity\", position = \"fill\", colour = \"black\") +\n  geom_text(aes(label = scales::percent(edu_prop)), position = position_stack(vjust = 0.5)) +\n\n\n  # if labels are desired\n  facet_grid(~Education, scales = \"free_x\", space = \"free_x\") +\n  theme(scale_fill_brewer(palette = \"RdYlGn\")) +\n  # theme(panel.spacing.x = unit(0, \"npc\")) + # if no spacing preferred between bars\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=50% height=50%}\n:::\n:::\n\n\nLet us now perform the base `chisq test`: We need a `table` and then the\n`chisq` test:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngss_table <- tally(DeathPenalty ~ Education, data = gss2002)\ngss_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Education\nDeathPenalty Bachelors Graduate  HS Jr Col Left HS\n      Favor        135       64 511     71     117\n      Oppose        71       50 200     16      72\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get the observed chi-square statistic\nobservedChi2 <- mosaic::chisq(tally(DeathPenalty ~ Education, data = gss2002))\nobservedChi2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nX.squared \n 23.45093 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Actual chi-square test\nstats::chisq.test(tally(DeathPenalty ~ Education, data = gss2002))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  tally(DeathPenalty ~ Education, data = gss2002)\nX-squared = 23.451, df = 4, p-value = 0.0001029\n```\n\n\n:::\n:::\n\n\nWe should now repeat the test with permutations on `Education`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnull_chisq <- do(10000) * chisq.test(tally(DeathPenalty ~ shuffle(Education), data = gss2002))\n\nhead(null_chisq)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"X.squared\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"alternative\"],\"name\":[5],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"data\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".row\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".index\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"4.525525\",\"2\":\"4\",\"3\":\"0.33953157\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"1\",\"_rn_\":\"X-squared...1\"},{\"1\":\"2.706790\",\"2\":\"4\",\"3\":\"0.60802705\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"2\",\"_rn_\":\"X-squared...2\"},{\"1\":\"8.748057\",\"2\":\"4\",\"3\":\"0.06771479\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"3\",\"_rn_\":\"X-squared...3\"},{\"1\":\"1.161623\",\"2\":\"4\",\"3\":\"0.88437586\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"4\",\"_rn_\":\"X-squared...4\"},{\"1\":\"3.148776\",\"2\":\"4\",\"3\":\"0.53324400\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"5\",\"_rn_\":\"X-squared...5\"},{\"1\":\"8.363959\",\"2\":\"4\",\"3\":\"0.07911977\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"6\",\"_rn_\":\"X-squared...6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngf_histogram(~X.squared, data = null_chisq) %>%\n  gf_vline(xintercept = observedChi2, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-31-1.png){fig-align='center' width=50% height=50%}\n:::\n\n```{.r .cell-code}\ngf_histogram(~p.value, data = null_chisq, binwidth = 0.1, center = 0.05)\n```\n\n::: {.cell-output-display}\n![](perm-tutorial_files/figure-html/unnamed-chunk-31-2.png){fig-align='center' width=50% height=50%}\n:::\n:::\n\n\nSo we would conclude that `Education` has a significant effect on\n`DeathPenalty` opinion!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}